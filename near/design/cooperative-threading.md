# 協調型スレッディング

エミュレータを書く上での最大の課題は、プログラミングコードが本質的にシリアルであるのに対し、エミュレートされたシステムには多くの、時には数十もの並列プロセスが同時に実行されていることです。

実際、レトロゲームシステムのエミュレータを書く際のオーバーヘッドのほとんどは、この環境におけるコンポーネント間の同期の管理です。

この記事では、私がエミュレータのために選んだアプローチである協調型マルチスレッドについて説明します。なお、これはいくつかのアプローチのうちの1つであり、私はここでどちらかのアプローチを支持するわけではありません。私は、その長所と短所を公平に紹介することに最善を尽くします。

## 同期の概要

ここで実現しようとしているのは、エミュレートされたコンポーネント間の同期です。

例えば、スーパーファミコンをエミュレートする場合、汎用CPU、オーディオAPU、ビデオPPU、サウンド出力DSPの4つの主要コンポーネントがあるとします。ここでは、説明のために少し物事を単純化しています（例えば、PPUプロセッサは2つあります）。

これらのチップはそれぞれ約20MHzのクロックレートで動作します。

エミュレータでは各チップをシリアルに、つまり1つずつ動作させる必要がありますが、本物のスーファミではこれらのチップをすべてパラレルに、つまり同時に動作させます。

エミュレータでは1つのチップを一定時間動作させた後、最初のチップに追いつくように他のチップを一定時間動作させて同期させます。

エミュレーションの精度が高ければ高いほど、この同期間隔はより細かいものになります。

1つの実装例としては、一度に1つのCPUオペコードを実行し、一度に1つのスキャンラインをレンダリングし、一度に1つのオーディオサンプルを生成することができます。そうすれば、1990年代後半に発売されたものと同程度の精度を持つ、非常に高速なスーファミのエミュレータができあがります。

他の実装例としては、CPUのオペコードサイクルを1つ分実行し、一度に1ピクセルのレンダリングを行い、オーディオサンプルの生成を32の異なるサイクルステージに分割することもできます。そうすると、bsnesのような高精度なエミュレータができます。

エミュレーションの同期間隔が細かくなればなるほど、あるエミュレートされたコンポーネントから別のコンポーネントへの切り替えも複雑になります。

例えば、CPUの命令をエミュレートしているときに、1サイクルごとにビデオレンダラに切り替えて1ピクセルだけ描画し、再びCPUに戻る必要があるとします。これでは技術的な複雑さが大幅に増してしまいますが、これを解消するのが協調スレッド処理です。

## 先取り型スレッディング

まず、当たり前のことを言わなければなりません。最近のプロセッサは多くのコアを持っていますし、まれにシングルコアのシステムがあったとしても、最近のOSはスレッド機能を備えており、複数のタスクをスレッドの形で並列に実行することができます。これを利用してエミュレータを作ることはできないのでしょうか？

答えは、残念ながらNO(できない)です。

スーファミを正確にエミュレートするには、エミュレートされた1秒間に数千万回の同期（コンテキストスイッチ）が必要になります。

CPUに実際のコアが1つしかない場合、技術的にはすべてのスレッドはシリアルで実行され、OSはカーネルモードでコンテキストスイッチを実行します。

ユーザーランドとカーネルモードの切り替えは、CPUにとって非常にコストが高く、どれだけ性能のいいCPUでも1秒間に数十万回程度です。

マルチコアCPUの場合は少し改善されますが、シングルコアでもマルチコアでも、PCのクロックレート(仮に3GHz)とスーファミのクロックレート(仮に20MHz)が異なるという事実に対処しなければなりません。

ここで各コンポーネントの同期を取るには、ロックやミューテックス、セマフォなどを追加して、エミュレートされた各スレッドの時間経過後に、あるスレッドが他のスレッドを待つようにします。しかし、これらのロックも非常にコストが高いです。

インターロックインクリメントやインターロックデクリメントのようなアトミックな命令に落とし込んだとしても、現代のCPUは巨大なパイプラインと各CPUコア間の低速なデータ線で大規模な並列化を行っているため、それに対抗することはできません。

## ステートマシーン

レトロなエミュレータの開発には、伝統的にステートマシンが用いられてきました。例として、サイクルベースのCPUインタプリタをステートマシンで分割する方法を大幅に簡略化した例を紹介します。

```c++
void CPU::executeInstructionCycle() {
  cycle++;
  if(cycle == 1) {
    opcode = readMemory(PC++);
    return;
  }
  if(FlagM)
  switch(opcode) {  //8-bit accumulator instructions
  case 0xb9:
    switch(cycle) {
    case 2:
      address = readMemory(PC++);
      return;
    case 3:
      address = readMemory(PC++) | address << 8;
      return;
    case 4:
      //possible penalty cycle when crossing 8-bit page boundaries:
      if(address >> 8 != address + Y >> 8) {
        return;
      }
      cycle++;  //cycle 4 not needed; fall through to cycle 5
    case 5:
      A = readMemory(address + Y);
      cycle = 0;  //end of instruction; start a new instruction next time
      return;
    }
  }
}
```

グラフィックレンダラをピクセル単位のタイムスライスに分割したり、オーディオジェネレータをサイクル単位のタイムスライスに分割したりと、それぞれに複雑な処理が必要です。

スーファミの場合、これだけでは足りません。CPUの1サイクルは、6〜12のマスタークロックサイクルで構成されており、アドレスバスに所定のアドレスが設定され、一定時間後に他のチップがバス上のデータを確認します。これを`bus hold delay`といいます。

基本的に、CPUがPPUからデータを読み出す場合、PPUが瞬時にデータを返すことは期待できません。また、CPUがPPUに書き込む場合にも少々時間が必要です。

そのため、読み出しをクロックサイクルに分割するためには、上記の`readMemory()`を呼び出すたびに、さらに細かいレベルのステートマシンを追加する必要があります。

```c++
void CPU::executeInstructionCycle() {
  if(cycle == 1) {
    opcode = readMemory(PC++);
    cycle = 2;
    return;
  }
  if(FlagM)
  switch(opcode) {  //8-bit accumulator instructions
  case 0xb9:
    switch(cycle) {
    case 2:
      switch(subcycle) {
      case 1:
        subcycle = 2;
        return;
      case 2:
        address = readMemory(PC++);
        subcycle = 1;
        return;
      }
    case 3:
      switch(subcycle) {
      case 1:
        subcycle = 2;
        return;
      case 2:
        address = readMemory(PC++) | address << 8;
        subcycle = 1;
        return;
      }
    case 4:
      //possible penalty cycle when crossing 8-bit page boundaries:
      if(address >> 8 != address + Y >> 8) {
        return;
      }
      cycle++;  //cycle 4 not needed; fall through to cycle 5
    case 5:
      switch(subcycle) {
      case 1:
        subcycle = 2;
        return;
      case 2:
        A = readMemory(address + Y);
        subcycle = 1;
        cycle = 0;  //end of instruction; start a new instruction next time
        return;
      }
    }
  }
}
```

なお、ここでは説明のために大幅に簡略化していることをご了承ください。

## 協調型スレッディング

協調型スレッディングの考え方は先取り型スレッディングと似ていますが、カーネルがスレッドを処理するのではなく、ユーザーランドのプロセスが代わりに処理します。

協調スレッドはすべてシリアルで実行されます。つまり、一度に1つしか実行されません。必要に応じてコンテキストスイッチで別のスレッドに切り替え、前回終了したところから再開することになります。

コルーチンとは異なり、各協調スレッドは独自のスタックフレームを持ちます。これは、1つのスレッドが、スタックフレームの奥深くにある数層の関数呼び出しになり得ることを意味します。

上で見たステートマシンのコードは、今では暗黙の了解となっています。それはスタックフレームの一部です。

そこで、上記のコードを書き換えると、次のようになります。

```c++
void CPU::executeInstruction() {
  opcode = readMemory(PC++);
  if(FlagM)
  switch(opcode) {  //8-bit accumulator instructions
  case 0xb9:
    address = readMemory(PC++);
    address = readMemory(PC++) | address << 8;
    if(address >> 8 != address + Y >> 8) wait(6);
    A = readMemory(address + Y);
  }
}

```

そう、そんなに劇的な違いがあるんですね。

どのような仕組みになっているのでしょうか？ そのためには、`readMemory()`関数の中を見てみましょう。

```c++
uint8_t CPU::readMemory(uint16_t address) {
  wait(2);
  uint8_t data = memory[address];
  wait(4);
  return data;
}
```

`wait()`の中も見てみましょう。

```c++
void CPU::wait(uint clockCycles) {
  apuCounter += clockCycles;
  while(apuCounter > 0) yield(apu);
}
```

`wait()`はクロックサイクルを消費するだけですが、CPUがAPUよりも先に進んだ状態になると、CPUは別スレッドで実行されているAPUに実行を譲り、APUは前回の続きから再開することになります。

APUが追いつき、CPUよりも先に進んだ時点で、APUはCPUに処理を譲り、CPUは最後の`yield()`した直後から再開します。

協調型スレッドは呼び出し(Call)よりもジャンプと考えることができます。APUでは、戻るのではなく、CPUにジャンプしただけです。結果だけ見ると戻っていますが。

技術的には、これを対称型の協調スレッドと呼びます。

典型的なcallとreturnのスタイルのように機能する非対称協調スレッドもありますが、私の意見では、多くのスレッドがすべて並行して実行されるエミュレーションには適していません。

CPUがAPUにジャンプし、APUがCPUに戻るのではなくPPUにジャンプする場合などがあり、そのような場合にcall/returnスタイルでは不都合です。

## 協調型スレッディングの最適化

ひとつ気になることがあります。それは、なぜクロックサイクルごとにCPUとAPUを同期させているのかということです。

例えば、CPUが、APUによってアクセスできない内部メモリから読み取っている場合、APUがそのまえに内部メモリに書き込んでメモリの内容を変更してしまうことを考える必要がないので同期を取る必要がありません。

基本的には、プロセッサ間で同期をとる場合は、エミュレートしたプロセッサを可能な限り小さなタイムスライスに分割し、それに合わせてステップを踏む必要があります。

メインのエミュレータのスケジューラは、CPUがあるサイクルでAPUにアクセスしようとしていないことを確認し、APUを少し動かす前にもっと多くのサイクルを走らせることができますが、実際にはステートマシンを通じてすでにオーバーヘッドを支払っていることになります。

しかし、協調スレッドは、私が「ジャストインタイム同期」と呼ぶ最適化の機会を与えてくれます。先ほどの例をもう少し詳しく説明しましょう。

```c++
uint8_t CPU::readMemory(uint16_t address) {
  wait(2);
  if(address >= 0x2140 && address <= 0x2143) {
    //this read is going to access shared memory with the APU.
    //in other words, the APU might change this value before we read it.
    //as such, we *must* catch up the APU to the CPU here:
    while(apuCounter > 0) yield(apu);
  }
  uint8_t data = memory[address];
  wait(4);
  return data;
}
```

```c++
void CPU::wait(uint clockCycles) {
  apuCounter += clockCycles;
}
```

上のコード例では、APUとの共有メモリ領域からの読み出しを試みるまで、CPUが動作し続けるようにしています。そして、共有メモリの場合は、APUがCPUに追いついてから読み出しを行うようにしました。

CPUがAPUとの同期を頻繁に取る必要がなければ、あるいは逆にAPUがCPUとの同期を頻繁に取る必要があれば、1秒間のコンテキストスイッチの回数は劇的に減少します。

スーファミの場合、私のエミュレータbsnesでは、1秒間に数百万回ではなく、1秒間に数千回しかCPUとAPUを同期させる必要がありませんでした。

## 協調型スレッディングの限界

しかし、2つのプロセッサ(ここではCPUとAPU)がお互いにすべてのメモリアドレス空間を共有している場合はどうでしょうか？

そうすると、（現在先行している）CPUがメモリを読み出そうとする前に、APUがメモリを変更するかどうかはわかりませんので、常に同期を取らなければなりません。

例えば、Nemesis社のExodusエミュレータのように、ロールバック機構を実装するなどの方法がありますが、その場合、このアプローチによるコードの簡素化の利点が失われてしまいます。

最悪の場合、協調スレッド処理は、ステートマシンと同じレベルのオーバーヘッドに戻ってしまいます。

## パイプラインのストール

実際には、最悪の場合、協調スレッド処理はステートマシン方式よりも多少遅くなります。

最近のCPUは、多くの処理を順不同に行うことが好きで、キューイングされた命令の深いパイプラインを構築しています。

協調スレッディングでスタックポインタを変更すると、パニックに陥る傾向があります。

例えて言えば、組み立てラインがあるとします。ラインに沿って、製品がゆっくりと組み立てられていきます。さて、順調に製品を組み立てている最中に、別の製品の注文が入り、待ちきれなくなったとします。しかし、組み立てラインは1本しかありませんでした。しかし、組立ラインは1本しかありません！組立ラインを止めて、すべての商品を外し、新しい商品の組立を始めなければなりません。1秒間に何千万回も、複数の製品の間を行ったり来たりしなければならないと想像すると、サイクル精度の高いレトロゲームのエミュレーションがなぜこれほどまでにマシンパワーを要求するのかがわかってきます。

ステートマシンも同じ問題を抱えています。ある命令領域（CPUエミュレーション）と別の命令領域（APUエミュレーション）を切り替えるのは、動作中に歯車が止まるようなもので、L1命令キャッシュを使い切ってしまうなどの問題があります。

しかし、スタックポインタを変更するために協調スレッドを必要とすることは、本当の意味でのペナルティです。非科学的ではありますが、私の個人的な観察によると、単一レベルのステートマシンを使ってプロセッサをエミュレートすることができれば、協調スレッド化されたアプローチよりもかなりの差で速く動作する傾向があります。

一方で、前述のCPUのオペコードの例のように、2段階（あるいは3段階以上）のステートマシンになると、協調スレッドモデルが性能面で明らかに勝ることになります。

また、協調スレッドがステートマシーン方式より遅い場合でも、先ほど説明したジャストインタイム同期を行うことができれば、勝負はつきません。

## 設計の選択肢

以上のことより、最大の効率を目指すのであれば、エミュレータは、協調型スレッドが最も効果的なところでは協調型スレッドを使用し、そうでないところではステートマシンを使用するように設計すべきでしょう。

私は一貫性を重視しているので、Higanエミュレータではすべてのプロセッサを協調スレッドでエミュレートすることにしました。

コードベース全体の一貫性とコードのシンプルさを確保するために、パフォーマンス上のペナルティを承知の上で、です。

## シリアライズ

おそらくエミュレータ開発者にとって、協調型スレッディングの最大の関心事はシリアライゼーション、つまりセーブステートの保存と読み込みです。

セーブステートは、進捗状況を保存したり復元したりするのに便利なだけでなく（容赦ないゲームでちょっとズルをするのにも最適です）、リアルタイム巻き戻しやランアヘッド入力レイテンシー削減などの機能を構成する要素でもあります（それぞれ別の記事を用意しています）。

ステートマシンを使用する場合、シリアル化とは、先ほどの例で言えば、オペコード、サイクル、サブサイクルなどの変数をすべて保存・復元することです。

しかし、協調型スレッディングを使用している場合、これらの情報は暗黙の了解となり、コールフレームやCPUコンテキストレジスタの形で個々のスタックに保存されます。

協調型スレッディングでシリアライズを実装することは可能ですが、複雑なテーマなので、このテーマについては別の記事を書きました。その記事はこちらからご覧いただけます。

[Cooperative Threading - Serialization](https://near.sh/articles/design/cooperative-serialization)

## 実装

ここまで読んでいただいて、協調スレッド処理を試してみようとお考えの方は、お使いの言語で協調型スレッドモデルの実装が必要です。

C++20では、コルーチンの拡張機能が提案されていますが、この記事を書いている時点では、動作する成熟した実装を持っていないので、エミュレーションに役立つかどうかはわかりません。おそらく最大の制限は、C++20のコルーチンがスタックレスであることで、中程度の複雑さのものであってもその可能性が大きく制限されてしまうことです。

代わりに、私はC89コードで独自の協調スレッドライブラリを開発しましたが、これはC++コードでも使用できます。そのソースコードは[ここ](https://github.com/bsnes-emu/bsnes/tree/master/libco)で見ることができます。

基本的には、コンテキストスイッチングを実装するために、サポートされている各アーキテクチャのアセンブラレベルまで落とす必要があります。なぜなら、CPUのコンテキストレジスタやスタックフレームを直接変更することは、ほとんどのまともなプログラミング言語では許可されていないからです。しかし、実際には難しくありません。x86のコンテキストスイッチはわずか12行のアセンブラコードです。x86のコンテキストスイッチはわずか12行のアセンブラコードで、32ビットARMはわずか3行です。

libcoはISCライセンスを取得しており、非常に多くのCPUアーキテクチャをサポートしていますので、必要に応じてこれらの作業をすべて自分で行う必要はありません。

もちろん、協調的スレッディングについて語る人の数だけ協調的スレッディングライブラリがありますので、自由に他のものを使ってもいいですし、自分で作ってもいいでしょう。

ほとんどの言語では、どこかにその実装があるでしょう。しかし、必ずしもそうとは限りません。

## 終わりに

いずれにしても、協調型スレッドは、ステートマシンを管理する負担を取り除くことで、コードを読みやすくするという点で、私のエミュレータに独自の利点を与えてくれていると思いますし、クロックサイクルに正確に対応することも簡単です。

繰り返しになりますが、これがレトロなエミュレータを書くための最良の方法だとは言いませんが、私にとっては非常に良い方法です。
